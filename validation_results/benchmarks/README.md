# Performance Benchmark Results

This directory contains performance benchmark results from AutoVoice testing on various GPU hardware.

## Directory Structure

```
benchmarks/
  ├── rtx_3080_ti/          # NVIDIA GeForce RTX 3080 Ti results
  ├── a100_40gb/            # NVIDIA A100 (40GB) results
  ├── rtx_3090/             # NVIDIA GeForce RTX 3090 results
  ├── rtx_4090/             # NVIDIA GeForce RTX 4090 results
  ├── t4/                   # NVIDIA Tesla T4 results
  ├── multi_gpu_comparison.json  # Aggregated comparison data
  ├── multi_gpu_comparison.md    # Human-readable comparison tables
  └── README.md             # This file
```

## Per-GPU Directory Contents

Each GPU directory contains:

- **`gpu_info.json`**: GPU model, CUDA version, driver version, compute capability
- **`benchmark_summary.json`**: Aggregated metrics (TTS latency, voice conversion RTF, memory, speedup)
- **`pytest_results.json`**: Results from `tests/test_performance.py`
- **`pipeline_profile.json`**: Pipeline profiling from `scripts/profile_performance.py`
- **`cuda_kernels_profile.json`**: CUDA kernel profiling from `scripts/profile_cuda_kernels.py`
- **`benchmark_report.md`**: Human-readable summary report

## Key Metrics

### TTS Performance
- **Synthesis Latency**: Time to synthesize 1 second of audio (target: <100ms)
- **Throughput**: Requests per second at optimal batch size
- **GPU Memory**: Peak VRAM usage during synthesis

### Voice Conversion Performance
- **Conversion Speed (RTF)**: Real-time factor for 30s song (target: ~1.0x)
- **Fast/Balanced/Quality Presets**: Performance across quality settings
- **GPU Memory**: Peak VRAM usage during conversion
- **CPU vs GPU Speedup**: Performance improvement over CPU (target: 10-50x)

### Quality Metrics
- **Pitch Accuracy**: RMSE in Hz (target: <10 Hz)
- **Speaker Similarity**: Cosine similarity percentage (target: >85%)
- **Naturalness Score**: Subjective quality rating (1-5 scale)

### CUDA Kernel Performance
- **Per-Kernel Timing**: Individual kernel execution times
- **Speedup vs Reference**: Comparison to CPU implementations (librosa, torchcrepe)

## Benchmark Conditions

- **PyTorch Version**: 2.5.1+cu121
- **CUDA Version**: 12.1
- **Test Audio**: 30-second synthetic singing voice @ 22.05kHz
- **Iterations**: 10 runs averaged (after 3 warmup runs)
- **Environment**: Idle system, no other GPU processes

## Reproducing Benchmarks

See [Performance Benchmarking Guide](../../docs/performance_benchmarking_guide.md) for detailed instructions.

Quick start:
```bash
# Generate test data
python scripts/generate_benchmark_test_data.py

# Run benchmarks
python scripts/run_comprehensive_benchmarks.py

# View results
cat validation_results/benchmarks/benchmark_report.md
```

## Multi-GPU Comparison

Aggregated results across all GPUs are available in:
- **JSON**: `multi_gpu_comparison.json`
- **Markdown**: `multi_gpu_comparison.md`

These files are generated by:
```bash
python scripts/aggregate_multi_gpu_results.py
```

## Notes

- Results may vary based on GPU temperature, power limit, and system load
- Quality metrics (pitch accuracy, speaker similarity) are consistent across GPUs
- Performance metrics (latency, throughput) vary significantly by GPU model
- CPU fallback is 12-32x slower than GPU but provides compatibility

## Last Updated

[Date will be automatically updated by benchmark scripts]

