"""Test Comment 3 Implementation: pred_audio generation for perceptual losses"""

import pytest
import torch
import numpy as np
from pathlib import Path
import sys

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from auto_voice.models.singing_voice_converter import SingingVoiceConverter


@pytest.fixture
def model_config():
    """Create minimal config for testing"""
    return {
        'singing_voice_converter': {
            'latent_dim': 192,
            'mel_channels': 80,
            'content_dim': 256,
            'pitch_dim': 192,
            'speaker_dim': 256,
            'hidden_channels': 192,
            'content_encoder': {
                'type': 'cnn_fallback',
                'output_dim': 256
            },
            'vocoder': {
                'use_vocoder': True
            },
            'audio': {
                'mel_scale': 'log',
                'sample_rate': 22050
            }
        }
    }


@pytest.fixture
def model(model_config):
    """Create model instance"""
    model = SingingVoiceConverter(model_config)
    model.eval()
    return model


def test_forward_with_use_vocoder_true(model):
    """Test that forward pass generates pred_audio when use_vocoder=True"""
    batch_size = 2
    T_audio = 16000
    T_mel = 100

    # Create dummy inputs
    source_audio = torch.randn(batch_size, T_audio)
    target_mel = torch.randn(batch_size, 80, T_mel)
    source_f0 = torch.rand(batch_size, T_mel) * 300 + 100  # F0 in 100-400 Hz
    target_speaker_emb = torch.randn(batch_size, 256)

    # Forward pass with use_vocoder=True (default)
    with torch.no_grad():
        outputs = model(
            source_audio=source_audio,
            target_mel=target_mel,
            source_f0=source_f0,
            target_speaker_emb=target_speaker_emb,
            use_vocoder=True
        )

    # Verify pred_audio is generated
    assert 'pred_audio' in outputs, "pred_audio should be in outputs when use_vocoder=True"
    assert outputs['pred_audio'].dim() == 2, "pred_audio should be 2D [B, T_audio]"
    assert outputs['pred_audio'].size(0) == batch_size, "pred_audio batch size should match input"

    print(f"✓ pred_audio generated: shape={outputs['pred_audio'].shape}")


def test_forward_with_use_vocoder_false(model):
    """Test that forward pass skips pred_audio when use_vocoder=False"""
    batch_size = 2
    T_audio = 16000
    T_mel = 100

    # Create dummy inputs
    source_audio = torch.randn(batch_size, T_audio)
    target_mel = torch.randn(batch_size, 80, T_mel)
    source_f0 = torch.rand(batch_size, T_mel) * 300 + 100
    target_speaker_emb = torch.randn(batch_size, 256)

    # Forward pass with use_vocoder=False
    with torch.no_grad():
        outputs = model(
            source_audio=source_audio,
            target_mel=target_mel,
            source_f0=source_f0,
            target_speaker_emb=target_speaker_emb,
            use_vocoder=False
        )

    # Verify pred_audio is NOT generated
    assert 'pred_audio' not in outputs, "pred_audio should NOT be in outputs when use_vocoder=False"

    print("✓ pred_audio correctly skipped when use_vocoder=False")


def test_forward_default_use_vocoder(model):
    """Test that use_vocoder defaults to True"""
    batch_size = 2
    T_audio = 16000
    T_mel = 100

    # Create dummy inputs
    source_audio = torch.randn(batch_size, T_audio)
    target_mel = torch.randn(batch_size, 80, T_mel)
    source_f0 = torch.rand(batch_size, T_mel) * 300 + 100
    target_speaker_emb = torch.randn(batch_size, 256)

    # Forward pass without specifying use_vocoder (should default to True)
    with torch.no_grad():
        outputs = model(
            source_audio=source_audio,
            target_mel=target_mel,
            source_f0=source_f0,
            target_speaker_emb=target_speaker_emb
        )

    # Verify pred_audio is generated by default
    assert 'pred_audio' in outputs, "pred_audio should be in outputs by default (use_vocoder=True)"

    print("✓ pred_audio generated by default (use_vocoder=True)")


def test_pred_audio_shape_consistency(model):
    """Test that pred_audio shape is consistent with vocoder sample rate"""
    batch_size = 4
    T_audio = 16000
    T_mel = 100

    # Create dummy inputs
    source_audio = torch.randn(batch_size, T_audio)
    target_mel = torch.randn(batch_size, 80, T_mel)
    source_f0 = torch.rand(batch_size, T_mel) * 300 + 100
    target_speaker_emb = torch.randn(batch_size, 256)

    # Forward pass
    with torch.no_grad():
        outputs = model(
            source_audio=source_audio,
            target_mel=target_mel,
            source_f0=source_f0,
            target_speaker_emb=target_speaker_emb,
            use_vocoder=True
        )

    # Check shape consistency
    pred_audio = outputs['pred_audio']
    assert pred_audio.dim() == 2, "pred_audio should be 2D"
    assert pred_audio.size(0) == batch_size, "pred_audio batch size should match"

    # Audio length should be reasonable for mel length
    # T_mel frames * hop_length = audio samples
    # For T_mel=100, hop_length=512 -> ~51200 samples
    assert pred_audio.size(1) > 0, "pred_audio should have non-zero length"

    print(f"✓ pred_audio shape consistent: {pred_audio.shape}")


def test_other_outputs_unchanged(model):
    """Test that adding pred_audio doesn't affect other outputs"""
    batch_size = 2
    T_audio = 16000
    T_mel = 100

    # Create dummy inputs
    source_audio = torch.randn(batch_size, T_audio)
    target_mel = torch.randn(batch_size, 80, T_mel)
    source_f0 = torch.rand(batch_size, T_mel) * 300 + 100
    target_speaker_emb = torch.randn(batch_size, 256)

    # Forward pass
    with torch.no_grad():
        outputs = model(
            source_audio=source_audio,
            target_mel=target_mel,
            source_f0=source_f0,
            target_speaker_emb=target_speaker_emb,
            use_vocoder=True
        )

    # Verify all expected keys exist
    required_keys = ['pred_mel', 'z_mean', 'z_logvar', 'z', 'u', 'logdet', 'cond', 'pred_audio']
    for key in required_keys:
        assert key in outputs, f"Output should contain '{key}'"

    # Verify pred_mel shape is unchanged
    assert outputs['pred_mel'].shape == target_mel.shape, "pred_mel shape should match target_mel"

    print(f"✓ All expected outputs present: {list(outputs.keys())}")


if __name__ == '__main__':
    # Run tests
    print("\n=== Testing Comment 3 Implementation ===\n")

    # Create fixtures
    config = {
        'singing_voice_converter': {
            'latent_dim': 192,
            'mel_channels': 80,
            'content_dim': 256,
            'pitch_dim': 192,
            'speaker_dim': 256,
            'hidden_channels': 192,
            'content_encoder': {
                'type': 'cnn_fallback',
                'output_dim': 256
            },
            'vocoder': {
                'use_vocoder': True
            },
            'audio': {
                'mel_scale': 'log',
                'sample_rate': 22050
            }
        }
    }

    model = SingingVoiceConverter(config)
    model.eval()

    # Run tests
    print("Test 1: Forward with use_vocoder=True")
    test_forward_with_use_vocoder_true(model)

    print("\nTest 2: Forward with use_vocoder=False")
    test_forward_with_use_vocoder_false(model)

    print("\nTest 3: Default use_vocoder behavior")
    test_forward_default_use_vocoder(model)

    print("\nTest 4: pred_audio shape consistency")
    test_pred_audio_shape_consistency(model)

    print("\nTest 5: Other outputs unchanged")
    test_other_outputs_unchanged(model)

    print("\n=== All Tests Passed ✓ ===\n")
