# ğŸ‰ AutoVoice Development Environment - Setup Complete!

## âœ… Installation Summary

Your AutoVoice development environment is now fully configured and ready to use!

### What Was Installed

| Component | Version | Status |
|-----------|---------|--------|
| **Python** | 3.12.12 | âœ… Installed |
| **PyTorch** | 2.5.1+cu121 | âœ… Installed |
| **TorchVision** | 0.20.1+cu121 | âœ… Installed |
| **TorchAudio** | 2.5.1+cu121 | âœ… Installed |
| **CUDA Runtime** | 12.1 | âœ… Bundled |
| **AutoVoice** | 1.0.0 | âœ… Installed (dev mode) |
| **Dependencies** | 111 packages | âœ… Installed |

### Environment Details

```bash
Conda Environment: autovoice
Location: ~/anaconda3/envs/autovoice
Python: 3.12.12
PyTorch: 2.5.1+cu121
Installation Mode: Editable (development)
```

---

## ğŸš€ Quick Start (3 Commands)

### 1. Activate Environment

```bash
conda activate autovoice
```

### 2. Download Models (Optional - ~590 MB)

```bash
python scripts/download_pretrained_models.py --required-only
```

### 3. Run a Demo

```bash
# Test imports
python -c "import auto_voice; print('âœ… AutoVoice', auto_voice.__version__)"

# Run inference demo
python examples/inference_demo.py

# Start web server
python -m auto_voice.web.app
```

---

## ğŸ“‹ What's Next?

### Option 1: Run Examples

```bash
cd examples/
python inference_demo.py              # Basic inference
python demo_voice_conversion.py       # Voice conversion
python demo_batch_conversion.py       # Batch processing
```

### Option 2: Start Development

```bash
# Make changes to code in src/auto_voice/
# Changes are immediately available (editable install)

# Run tests
pytest tests/test_imports.py -v

# Check your changes
python -c "from auto_voice import YourNewFeature"
```

### Option 3: Start Web Server

```bash
# Start server on port 5000
python -m auto_voice.web.app

# Test API
curl http://localhost:5000/health
```

### Option 4: Run Tests

```bash
# Quick smoke test
pytest tests/test_imports.py -v

# Full test suite
pytest tests/ -v

# With coverage
pytest tests/ --cov=auto_voice --cov-report=html
```

---

## ğŸ“š Documentation

### Essential Guides

- **[Development Setup](docs/DEV_ENVIRONMENT_SETUP.md)** - Complete development guide
- **[Quick Start](QUICK_START.md)** - Fast path to running the system
- **[README](README.md)** - Project overview and features
- **[API Documentation](docs/API.md)** - API reference

### Technical Docs

- **[Model Guide](docs/MODEL_GUIDE.md)** - Model architecture and usage
- **[Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Production deployment
- **[Testing Guide](docs/TESTING_GUIDE.md)** - Testing infrastructure

---

## ğŸ”§ Common Commands

### Environment Management

```bash
# Activate environment
conda activate autovoice

# Deactivate environment
conda deactivate

# List installed packages
conda list

# Update package
pip install <package> --upgrade
```

### Development

```bash
# Reinstall in dev mode
pip install -e .

# Format code
black src/ tests/

# Sort imports
isort src/ tests/

# Run linter
flake8 src/ tests/
```

### Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_inference.py -v

# Run with coverage
pytest tests/ --cov=auto_voice --cov-report=html

# Run specific test
pytest tests/test_inference.py::test_basic_inference -v
```

### GPU Monitoring

```bash
# Check GPU status
nvidia-smi

# Monitor GPU usage
nvitop

# Check CUDA availability
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
```

---

## ğŸ¯ Project Structure

```
autovoice/
â”œâ”€â”€ src/auto_voice/          # Main package (edit here)
â”‚   â”œâ”€â”€ inference/           # Inference engines
â”‚   â”œâ”€â”€ models/              # Model definitions
â”‚   â”œâ”€â”€ training/            # Training pipelines
â”‚   â”œâ”€â”€ audio/               # Audio processing
â”‚   â”œâ”€â”€ gpu/                 # GPU management
â”‚   â”œâ”€â”€ utils/               # Utilities
â”‚   â””â”€â”€ web/                 # Web server & API
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ inference/           # Inference tests
â”‚   â”œâ”€â”€ models/              # Model tests
â”‚   â”œâ”€â”€ gpu/                 # GPU tests
â”‚   â””â”€â”€ integration/         # Integration tests
â”œâ”€â”€ examples/                # Example scripts
â”œâ”€â”€ config/                  # Configuration files
â”œâ”€â”€ models/                  # Pre-trained models (download)
â”œâ”€â”€ scripts/                 # Utility scripts
â””â”€â”€ docs/                    # Documentation
```

---

## âš ï¸ Important Notes

### CUDA Availability

**Status**: `CUDA Available: False`

This is **expected** if you're running in:
- WSL2 (Windows Subsystem for Linux)
- System without NVIDIA GPU
- Docker without GPU passthrough

**Impact**: The system will automatically fall back to CPU mode. All features work, just slower.

**To enable GPU**:
1. Ensure NVIDIA GPU is present
2. Install NVIDIA drivers (535+)
3. For WSL2: Install CUDA toolkit in Windows
4. For Docker: Use `--gpus all` flag

### Python 3.13 Issue - RESOLVED âœ…

The original Python 3.13 segfault issue has been **completely resolved** by downgrading to Python 3.12.12, which has stable PyTorch 2.5.1 support.

---

## ğŸ› Troubleshooting

### Import Errors

```bash
# Reinstall package
pip install -e .
```

### Port Already in Use

```bash
# Use different port
python -m auto_voice.web.app --port 8080
```

### Missing Models

```bash
# Download required models
python scripts/download_pretrained_models.py --required-only
```

### Memory Issues

```bash
# Reduce batch size
export AUTOVOICE_BATCH_SIZE=1
```

---

## ğŸ“ Getting Help

- **Documentation**: Check `docs/` directory
- **Examples**: See `examples/` directory
- **Tests**: Look at `tests/` for usage examples
- **Issues**: Create GitHub issue with details

---

## ğŸ‰ You're All Set!

Your development environment is ready. Start coding! ğŸš€

```bash
conda activate autovoice
python examples/inference_demo.py
```

