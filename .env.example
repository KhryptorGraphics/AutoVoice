# Environment Configuration for Auto Voice Cloning

# Model Configuration
MODEL_DIR=models/
CACHE_DIR=~/.cache/auto_voice/
USE_GPU=auto  # auto, true, or false
DOWNLOAD_TIMEOUT=3600

# Model URLs (optional, will use defaults from models.yaml if not set)
# HUBERT_MODEL_URL=https://huggingface.co/facebook/hubert-base-ls960/resolve/main/pytorch_model.bin
# HIFIGAN_MODEL_URL=https://huggingface.co/nvidia/hifigan/resolve/main/generator_v3
# SPEAKER_ENCODER_URL=https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb/resolve/main/embedding_model.ckpt

# Device Configuration
DEVICE=cpu  # cpu or cuda
TORCH_DEVICE=cpu  # Override torch device if needed

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=auto_voice.log

# Pipeline Configuration
USE_MOCK_MODELS=false  # Set to true for testing without downloading models
ENABLE_MODEL_WARMUP=true  # Warmup models during initialization
