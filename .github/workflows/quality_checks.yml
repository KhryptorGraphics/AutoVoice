name: Quality Checks

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  quality-validation:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Generate synthetic test data
        run: |
          python scripts/generate_test_data.py \
            --output data/evaluation/ \
            --num-samples 6 \
            --seed 42

      - name: Run quality validation tests
        run: |
          pytest -m quality -v tests/test_end_to_end.py::TestQualityValidation

      - name: Run quality evaluation
        run: |
          python examples/evaluate_voice_conversion.py \
            --test-metadata data/evaluation/test_set.json \
            --output-dir evaluation_results \
            --no-align-audio \
            --validate-targets \
            --min-pitch-correlation 0.8 \
            --max-pitch-rmse-hz 10.0 \
            --min-speaker-similarity 0.85

      - name: Upload evaluation results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-results
          path: evaluation_results/

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const markdownPath = 'evaluation_results/evaluation_report.md';
            if (fs.existsSync(markdownPath)) {
              const markdown = fs.readFileSync(markdownPath, 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: '## Quality Evaluation Results\n\n' + markdown
              });
            }

  quality-regression:
    runs-on: ubuntu-latest
    needs: [quality-validation]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Download baseline metrics
        id: download-baseline
        continue-on-error: true
        uses: actions/download-artifact@v3
        with:
          name: quality-baseline
          path: .github/

      - name: Create baseline if not exists
        if: steps.download-baseline.outcome == 'failure'
        run: |
          mkdir -p .github
          if [ ! -f .github/quality_baseline.json ]; then
            echo '{
              "version": "1.0",
              "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
              "branch": "'${GITHUB_REF_NAME}'",
              "commit": "'${GITHUB_SHA}'",
              "metrics": {
                "pitch_rmse_hz": 10.0,
                "pitch_correlation": 0.80,
                "speaker_similarity": 0.85,
                "overall_quality_score": 0.75,
                "processing_rtf_cpu": 20.0,
                "processing_rtf_gpu": 5.0
              },
              "thresholds": {
                "pitch_rmse_hz_max_increase": 2.0,
                "pitch_correlation_min_decrease": 0.05,
                "speaker_similarity_min_decrease": 0.05,
                "overall_quality_min": 0.70,
                "rtf_max_increase_percent": 20.0
              }
            }' > .github/quality_baseline.json
          fi

      - name: Generate synthetic test data
        run: |
          python scripts/generate_test_data.py \
            --output data/evaluation/ \
            --num-samples 6 \
            --seed 42

      - name: Run regression tests
        id: regression-tests
        continue-on-error: true
        run: |
          pytest -v \
            tests/test_performance.py::TestQualityRegressionDetection \
            --baseline-file=.github/quality_baseline.json \
            --output-file=regression_results.json \
            --junitxml=regression_results.xml

      - name: Generate comparison report
        if: always()
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path

          # Load baseline
          baseline_path = Path('.github/quality_baseline.json')
          if baseline_path.exists():
              with open(baseline_path) as f:
                  baseline = json.load(f)
          else:
              baseline = {'metrics': {}}

          # Load current results if available
          results_path = Path('regression_results.json')
          if results_path.exists():
              with open(results_path) as f:
                  current = json.load(f)
          else:
              current = {'metrics': {}}

          # Generate markdown report
          report = ['# Quality Regression Analysis\n']
          report.append(f'**Baseline**: {baseline.get(\"timestamp\", \"N/A\")} (commit: {baseline.get(\"commit\", \"N/A\")[:8]})\n')
          report.append(f'**Current**: {current.get(\"timestamp\", \"N/A\")} (commit: {current.get(\"commit\", \"N/A\")[:8]})\n\n')
          report.append('## Metric Comparison\n\n')
          report.append('| Metric | Baseline | Current | Change | Status |\n')
          report.append('|--------|----------|---------|--------|--------|\n')

          baseline_metrics = baseline.get('metrics', {})
          current_metrics = current.get('metrics', {})
          thresholds = baseline.get('thresholds', {})

          has_regression = False

          for metric in sorted(set(baseline_metrics.keys()) | set(current_metrics.keys())):
              baseline_val = baseline_metrics.get(metric, 0.0)
              current_val = current_metrics.get(metric, 0.0)

              if baseline_val == 0:
                  change = 0
                  change_str = 'N/A'
              else:
                  change = ((current_val - baseline_val) / baseline_val) * 100
                  change_str = f'{change:+.1f}%'

              # Determine status based on metric type
              status = '✅'
              if 'rmse' in metric.lower() and current_val > baseline_val:
                  if change > thresholds.get('pitch_rmse_hz_max_increase', 2.0):
                      status = '❌ REGRESSION'
                      has_regression = True
                  elif change > thresholds.get('pitch_rmse_hz_max_increase', 2.0) / 2:
                      status = '⚠️ Warning'
              elif 'correlation' in metric.lower() or 'similarity' in metric.lower() or 'quality' in metric.lower():
                  if current_val < baseline_val - thresholds.get('pitch_correlation_min_decrease', 0.05):
                      status = '❌ REGRESSION'
                      has_regression = True
                  elif current_val < baseline_val - thresholds.get('pitch_correlation_min_decrease', 0.05) / 2:
                      status = '⚠️ Warning'
              elif 'rtf' in metric.lower():
                  if change > thresholds.get('rtf_max_increase_percent', 20.0):
                      status = '❌ REGRESSION'
                      has_regression = True
                  elif change > thresholds.get('rtf_max_increase_percent', 20.0) / 2:
                      status = '⚠️ Warning'

              report.append(f'| {metric} | {baseline_val:.4f} | {current_val:.4f} | {change_str} | {status} |\n')

          report.append('\n## Summary\n\n')
          if has_regression:
              report.append('❌ **Quality regression detected!** Some metrics have degraded beyond acceptable thresholds.\n')
              sys.exit(1)
          else:
              report.append('✅ **No regression detected.** All metrics are within acceptable ranges.\n')

          # Write report
          Path('regression_report.md').write_text(''.join(report))
          print(''.join(report))
          " || echo "Report generation failed, but continuing..."

      - name: Upload regression artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: regression-analysis
          path: |
            regression_results.json
            regression_results.xml
            regression_report.md
            .github/quality_baseline.json

      - name: Update baseline on main
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # Update baseline with current metrics if tests passed
          if [ -f regression_results.json ]; then
            python -c "
            import json
            from datetime import datetime
            from pathlib import Path

            # Load current results
            with open('regression_results.json') as f:
                current = json.load(f)

            # Create new baseline
            baseline = {
                'version': '1.0',
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'branch': '${GITHUB_REF_NAME}',
                'commit': '${GITHUB_SHA}',
                'metrics': current.get('metrics', {}),
                'thresholds': current.get('thresholds', {
                    'pitch_rmse_hz_max_increase': 2.0,
                    'pitch_correlation_min_decrease': 0.05,
                    'speaker_similarity_min_decrease': 0.05,
                    'overall_quality_min': 0.70,
                    'rtf_max_increase_percent': 20.0
                })
            }

            # Save baseline
            Path('.github/quality_baseline.json').write_text(json.dumps(baseline, indent=2))
            print('Baseline updated successfully')
            "
          fi

      - name: Upload updated baseline
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: actions/upload-artifact@v3
        with:
          name: quality-baseline
          path: .github/quality_baseline.json
          retention-days: 90

      - name: Comment PR with regression analysis
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const reportPath = 'regression_report.md';
            if (fs.existsSync(reportPath)) {
              const report = fs.readFileSync(reportPath, 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            }
