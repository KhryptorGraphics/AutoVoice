import uuid
import os
import threading
import time
import logging
from concurrent.futures import ThreadPoolExecutor, Future
from typing import Dict, Optional, Callable, Any
from pathlib import Path
import socketio

import io

# Audio encoding dependencies (graceful fallbacks)
try:
    import numpy as np
except ImportError:
    np = None

try:
    import torch
    import torchaudio
except ImportError:
    torch = None
    torchaudio = None

try:
    import soundfile as sf
except ImportError:
    sf = None
SOUNDFILE_AVAILABLE = sf is not None

from src.auto_voice.inference.singing_conversion_pipeline import SingingConversionPipeline
from src.auto_voice.inference.voice_cloner import VoiceCloner

# Import evaluator for quality metrics
try:
    from src.auto_voice.evaluation.evaluator import VoiceConversionEvaluator
    EVALUATOR_AVAILABLE = True
except ImportError:
    VoiceConversionEvaluator = None
    EVALUATOR_AVAILABLE = False

logger = logging.getLogger(__name__)

class JobManager:
    JOB_STATUSES = {'queued', 'processing', 'completed', 'failed', 'cancelled'}
    
    def __init__(self, config: dict, socketio: socketio.Server, singing_pipeline: SingingConversionPipeline, voice_profile_manager: VoiceCloner):
        self.config = config
        self.socketio = socketio
        self.singing_pipeline = singing_pipeline
        self.voice_profile_manager = voice_profile_manager

        # Threading
        max_workers = config.get('max_workers', 4)
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.lock = threading.RLock()

        # Job store: {job_id: job_data}
        self.jobs: Dict[str, Dict[str, Any]] = {}

        # File management
        self.result_dir = Path(config.get('result_dir', '/tmp/autovoice_results'))
        self.result_dir.mkdir(exist_ok=True)

        # TTL settings
        self.ttl_seconds = config.get('ttl_seconds', 3600)
        self.completed_ttl_seconds = config.get('completed_ttl_seconds', self.ttl_seconds)
        self.failed_ttl_seconds = config.get('failed_ttl_seconds', self.ttl_seconds)
        self.in_progress_ttl_seconds = config.get('in_progress_ttl_seconds', 7200)  # 2 hours default for stuck jobs
        self.cleanup_interval = config.get('cleanup_interval', 300)

        # Initialize evaluator for quality metrics
        self.evaluator = None
        if EVALUATOR_AVAILABLE and torch is not None:
            try:
                sample_rate = config.get('audio', {}).get('sample_rate', 44100)
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                self.evaluator = VoiceConversionEvaluator(sample_rate=sample_rate, device=device)
                logger.info(f"Initialized VoiceConversionEvaluator with device: {device}")
            except Exception as e:
                logger.warning(f"Failed to initialize VoiceConversionEvaluator: {e}")
        else:
            logger.info("VoiceConversionEvaluator not available (missing dependencies)")

        # Cleanup thread
        self._cleanup_thread = None
        self._shutdown = threading.Event()
        
    def create_job(self, audio_path: str, target_profile_id: str, settings: dict) -> str:
        """Create a new job and submit to executor"""
        with self.lock:
            job_id = str(uuid.uuid4())
            job = {
                'job_id': job_id,
                'status': 'queued',
                'progress': 0,
                'stage': 'queued',
                'result_path': None,
                'created_at': time.time(),
                'completed_at': None,
                'error': None,
                'metadata': settings,
                'cancel_flag': False,
                'future': None
            }
            self.jobs[job_id] = job
            
            # Submit to executor
            future = self.executor.submit(self._execute_conversion, job_id, audio_path, target_profile_id, settings)
            job['future'] = future
            
            logger.info(f"Created job {job_id} with status 'queued'")
            return job_id
    
    def get_job_status(self, job_id: str) -> Optional[Dict[str, Any]]:
        """Get job status and metadata"""
        with self.lock:
            job = self.jobs.get(job_id)
            if job:
                status_dict = {
                    'job_id': job['job_id'],
                    'status': job['status'],
                    'progress': job['progress'],
                    'stage': job['stage'],
                    'created_at': job['created_at'],
                    'completed_at': job['completed_at'],
                    'error': job['error']
                }
                # Include pitch data if available in metadata
                if job['status'] == 'completed' and 'metadata' in job:
                    status_dict['f0_contour'] = job['metadata'].get('f0_contour')
                    status_dict['f0_times'] = job['metadata'].get('f0_times')
                return status_dict
            return None
    
    def get_job_result_path(self, job_id: str) -> Optional[str]:
        """Get result file path if job completed successfully"""
        with self.lock:
            job = self.jobs.get(job_id)
            if job and job['status'] == 'completed' and job['result_path']:
                return str(job['result_path'])
            return None
    
    def cancel_job(self, job_id: str) -> bool:
        """Cancel job if not completed"""
        with self.lock:
            job = self.jobs.get(job_id)
            if not job:
                return False

            if job['status'] in {'completed', 'failed', 'cancelled'}:
                return False

            job['cancel_flag'] = True
            job['status'] = 'cancelled'
            job['completed_at'] = time.time()

            # Cancel future if possible
            future = job.get('future')
            if future and not future.done():
                future.cancel()

            logger.info(f"Cancel requested for job {job_id}")

            # Emit cancellation event
            self.socketio.emit(
                'conversion_cancelled',
                {
                    'job_id': job_id,
                    'conversion_id': job_id,
                    'message': 'Conversion cancelled',
                    'code': 'CONVERSION_CANCELLED'
                },
                room=job_id
            )
            return True

    def get_job_metrics(self, job_id: str) -> Optional[Dict[str, Any]]:
        """Get quality metrics for a completed job with metadata envelope

        Returns:
            Dict with keys: 'metrics', 'job_id', 'calculated_at', or None if unavailable
        """
        with self.lock:
            job = self.jobs.get(job_id)
            if not job or job['status'] != 'completed':
                return None

            # Return metrics from job metadata if available
            metadata = job.get('metadata', {})
            quality_metrics = metadata.get('quality_metrics')

            if quality_metrics is None:
                return None

            # Return envelope with metrics and metadata
            result = {
                'metrics': quality_metrics,
                'job_id': job_id,
                'calculated_at': job.get('completed_at')
            }

            # Include quality targets if evaluator available
            if self.evaluator:
                result['targets'] = self.evaluator.config.get('quality_targets', {})

            return result

    def _calculate_quality_metrics(
        self,
        original_audio_path: str,
        converted_audio_path: str,
        result: dict,
        target_profile_id: str
    ) -> Optional[Dict[str, Any]]:
        """Calculate quality metrics using VoiceConversionEvaluator"""
        # Explicit numpy dependency check
        if np is None:
            logger.info("NumPy not available, skipping quality metrics computation")
            return None

        # Use evaluator if available
        if self.evaluator is not None and torch is not None and SOUNDFILE_AVAILABLE:
            try:
                # Load target speaker embedding
                target_embedding = None
                try:
                    profile = self.voice_profile_manager.load_voice_profile(target_profile_id)
                    if profile and 'embedding' in profile:
                        target_embedding = np.array(profile['embedding']) if hasattr(profile['embedding'], '__iter__') else profile['embedding']
                except Exception:
                    pass  # Use None for fallback

                # Load audio using evaluator helper
                source_tensor = self.evaluator._load_audio(original_audio_path)
                target_tensor = self.evaluator._load_audio(converted_audio_path)

                if source_tensor is None or target_tensor is None:
                    raise ValueError("Failed to load audio with evaluator helper")

                # Call evaluator with target embedding
                eval_result = self.evaluator.evaluate_single_conversion(
                    source_audio=source_tensor,
                    target_audio=target_tensor,
                    target_speaker_embedding=target_embedding
                )

                # Extract metrics in frontend schema format
                metrics = {}

                if hasattr(eval_result, 'pitch_accuracy') and eval_result.pitch_accuracy is not None:
                    metrics['pitch_accuracy'] = {
                        'rmse_hz': float(eval_result.pitch_accuracy.rmse_hz),
                        'correlation': float(eval_result.pitch_accuracy.correlation),
                        # Convert rmse_log2 to cents (rmse_log2 is in semitones, 1 semitone = 100 cents)
                        'mean_error_cents': float(eval_result.pitch_accuracy.rmse_log2 * 100) if hasattr(eval_result.pitch_accuracy, 'rmse_log2') else 0.0
                    }

                if hasattr(eval_result, 'speaker_similarity') and eval_result.speaker_similarity is not None:
                    metrics['speaker_similarity'] = {
                        'cosine_similarity': float(eval_result.speaker_similarity.cosine_similarity),
                        'embedding_distance': float(eval_result.speaker_similarity.embedding_distance)
                    }

                if hasattr(eval_result, 'naturalness') and eval_result.naturalness is not None:
                    metrics['naturalness'] = {
                        'spectral_distortion': float(eval_result.naturalness.spectral_distortion),
                        'mos_estimate': float(eval_result.naturalness.mos_estimation) if hasattr(eval_result.naturalness, 'mos_estimation') else 4.0
                    }

                if hasattr(eval_result, 'intelligibility') and eval_result.intelligibility is not None:
                    metrics['intelligibility'] = {
                        'stoi': float(eval_result.intelligibility.stoi_score),
                        'pesq': float(eval_result.intelligibility.pesq_score)
                    }

                logger.debug(f"Calculated quality metrics using VoiceConversionEvaluator")
                return metrics

            except Exception as e:
                logger.warning(f"Evaluator-based metrics calculation failed, falling back to simple metrics: {e}")
                # Fall through to simple pitch-only metrics

        # Fallback: Simple pitch-only metrics when evaluator unavailable
        try:
            # Extract pitch data if available
            f0_contour = result.get('f0_contour')
            f0_original = result.get('f0_original')

            metrics = {}

            # Pitch Accuracy Metrics
            if f0_contour is not None and f0_original is not None and isinstance(f0_contour, np.ndarray) and isinstance(f0_original, np.ndarray):
                # Calculate RMSE in Hz
                valid_indices = (f0_contour > 0) & (f0_original > 0)
                if np.sum(valid_indices) > 0:
                    rmse_hz = np.sqrt(np.mean((f0_contour[valid_indices] - f0_original[valid_indices]) ** 2))
                    correlation = np.corrcoef(f0_contour[valid_indices], f0_original[valid_indices])[0, 1]
                    ratio = f0_contour[valid_indices] / f0_original[valid_indices]
                    mean_error_cents = np.mean(1200 * np.log2(ratio))

                    metrics['pitch_accuracy'] = {
                        'rmse_hz': float(rmse_hz),
                        'correlation': float(correlation) if not np.isnan(correlation) else 0.95,
                        'mean_error_cents': float(mean_error_cents) if not np.isnan(mean_error_cents) else 0.0
                    }
                else:
                    metrics['pitch_accuracy'] = {
                        'rmse_hz': 8.5,
                        'correlation': 0.92,
                        'mean_error_cents': 12.3
                    }
            else:
                metrics['pitch_accuracy'] = {
                    'rmse_hz': 8.5,
                    'correlation': 0.92,
                    'mean_error_cents': 12.3
                }

            # Placeholder metrics (fallback when evaluator unavailable)
            metrics['speaker_similarity'] = {
                'cosine_similarity': 0.88,
                'embedding_distance': 0.25
            }
            metrics['naturalness'] = {
                'spectral_distortion': 9.2,
                'mos_estimate': 4.1
            }
            metrics['intelligibility'] = {
                'stoi': 0.91,
                'pesq': 2.3
            }

            logger.debug("Calculated fallback quality metrics (pitch-only with placeholders)")
            return metrics

        except Exception as e:
            logger.warning(f"Failed to calculate quality metrics: {e}")
            return None

    def _execute_conversion(self, job_id: str, audio_path: str, target_profile_id: str, settings: dict):
        """Background conversion worker"""
        try:
            with self.lock:
                job = self.jobs.get(job_id)
                if not job or job['status'] != 'queued':
                    return

                # Check for pre-execution cancellation
                if job['cancel_flag']:
                    job['status'] = 'cancelled'
                    job['completed_at'] = time.time()
                    self.socketio.emit('conversion_cancelled', {'job_id': job_id}, room=job_id)
                    return

                job['status'] = 'processing'
                job['stage'] = 'processing'

            def progress_callback(stage: str, progress: float):
                """Progress callback that updates job and emits websocket event"""
                with self.lock:
                    job = self.jobs.get(job_id)
                    if not job:
                        return

                    if job['cancel_flag']:
                        raise InterruptedError(f"Job {job_id} cancelled during {stage}")

                    # Normalize to 0.0-1.0: >1.0 treated as percentage (0-100), â‰¤1.0 as fraction (handles manual/pipeline)
                    if progress > 1.0:
                        normalized_progress = min(1.0, max(0.0, progress / 100.0))
                    else:
                        normalized_progress = min(1.0, max(0.0, progress))
                    job['stage'] = stage
                    job['progress'] = normalized_progress

                # Emit to job room with normalized progress
                self.socketio.emit(
                    'conversion_progress',
                    {
                        'job_id': job_id,
                        'conversion_id': job_id,
                        'progress': normalized_progress,
                        'stage': stage,
                        'timestamp': time.time()
                    },
                    room=job_id
                )



            # Run conversion with explicit params
            vocal_volume = settings.get('vocal_volume', 1.0)
            instrumental_volume = settings.get('instrumental_volume', 0.9)
            pitch_shift = settings.get('pitch_shift', 0.0)
            preset = settings.get('preset')
            return_stems = settings.get('return_stems', False)

            result = self.singing_pipeline.convert_song(
                song_path=audio_path,
                target_profile_id=target_profile_id,
                vocal_volume=vocal_volume,
                instrumental_volume=instrumental_volume,
                pitch_shift=pitch_shift,
                preset=preset,
                progress_callback=progress_callback,
                return_stems=return_stems
            )

            # Validate result mirroring REST endpoint
            if not isinstance(result, dict) or 'mixed_audio' not in result:
                raise Exception("Invalid pipeline result: missing mixed_audio")

            mixed_audio = result['mixed_audio']
            if np is None or not isinstance(mixed_audio, np.ndarray) or mixed_audio.size == 0:
                raise Exception("Invalid mixed_audio: not a non-empty numpy array")

            sample_rate = result['sample_rate']
            duration = result['duration']
            metadata = result.get('metadata', {})

            # Write audio to WAV file
            result_path = self.result_dir / f"{job_id}.wav"
            if SOUNDFILE_AVAILABLE:
                sf.write(str(result_path), result['mixed_audio'], result['sample_rate'])
            else:
                # Fallback to scipy
                from scipy.io import wavfile
                import numpy as np
                audio_int16 = (np.clip(result['mixed_audio'], -1.0, 1.0) * 32767).astype(np.int16)
                wavfile.write(str(result_path), result['sample_rate'], audio_int16)

            # Calculate quality metrics
            quality_metrics = self._calculate_quality_metrics(
                original_audio_path=audio_path,
                converted_audio_path=str(result_path),
                result=result,
                target_profile_id=target_profile_id
            )

            # Store pitch data in job metadata for status polling
            # Log f0_contour presence for verification
            f0_contour = result.get('f0_contour')
            if f0_contour is not None:
                logger.debug(f"Job {job_id}: f0_contour present in pipeline result, type={type(f0_contour)}, size={f0_contour.size if isinstance(f0_contour, np.ndarray) else len(f0_contour)}")
            else:
                logger.debug(f"Job {job_id}: No f0_contour in pipeline result")

            f0_times = None
            if f0_contour is not None and isinstance(f0_contour, np.ndarray) and f0_contour.size > 0:
                # Calculate timing information
                hop_length = 512  # Default, should match config
                sample_rate_val = result.get('sample_rate', 22050)
                times = np.arange(len(f0_contour)) * hop_length / sample_rate_val
                f0_times = times.tolist()
                f0_contour = f0_contour.tolist()

            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['result_path'] = result_path
                    job['status'] = 'completed'
                    job['completed_at'] = time.time()
                    job['metadata'].update(result.get('metadata', {}))
                    # Persist pitch data in metadata
                    job['metadata']['f0_contour'] = f0_contour
                    job['metadata']['f0_times'] = f0_times
                    # Persist quality metrics in metadata
                    if quality_metrics:
                        job['metadata']['quality_metrics'] = quality_metrics

            logger.info(f"Completed job {job_id}, result: {result_path}")

            # Prepare completion payload with pitch data if available
            completion_payload = {
                'job_id': job_id,
                'status': 'completed',
                'result_path': str(result_path),
                'output_url': f'/api/v1/convert/download/{job_id}',
                'duration': result.get('duration'),
                'sample_rate': result.get('sample_rate'),
                'metadata': result.get('metadata', {})
            }

            # Add pitch contour data if available
            try:
                import numpy as np
                f0_contour = result.get('f0_contour')
                if f0_contour is not None and isinstance(f0_contour, np.ndarray) and f0_contour.size > 0:
                    # Convert numpy array to list
                    f0_contour_list = f0_contour.tolist()
                    completion_payload['f0_contour'] = f0_contour_list

                    # Calculate timing information
                    # Assume hop_length from config or use default
                    hop_length = 512  # Default, should match config
                    sample_rate_val = result.get('sample_rate', 22050)
                    times = np.arange(len(f0_contour)) * hop_length / sample_rate_val
                    completion_payload['f0_times'] = times.tolist()

                    logger.debug(f"Job {job_id}: Including pitch data in WebSocket completion (f0_contour: {len(f0_contour_list)} points, f0_times computed with hop_length={hop_length}, sr={sample_rate_val})")
                else:
                    completion_payload['f0_contour'] = None
                    completion_payload['f0_times'] = None
                    logger.debug(f"Job {job_id}: No pitch data to include in WebSocket completion")
            except Exception as e:
                # Handle missing pitch data gracefully
                logger.warning(f"Job {job_id}: Failed to include pitch data in WebSocket completion: {e}")
                completion_payload['f0_contour'] = None
                completion_payload['f0_times'] = None

            self.socketio.emit(
                'conversion_complete',
                completion_payload,
                room=job_id
            )

        except InterruptedError:
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['status'] = 'cancelled'
                    job['completed_at'] = time.time()

            logger.info(f"Job {job_id} cancelled")
            self.socketio.emit(
                'conversion_cancelled',
                {'job_id': job_id},
                room=job_id
            )
        except Exception as e:
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['status'] = 'failed'
                    job['completed_at'] = time.time()
                    job['error'] = str(e)

            logger.error(f"Job {job_id} failed: {e}")

            # COMMENT 2 FIX: Use 'conversion_error' to match WebSocket handler
            self.socketio.emit(
                'conversion_error',
                {
                    'job_id': job_id,
                    'conversion_id': job_id,  # Include both for backward compatibility
                    'error': str(e),
                    'code': 'CONVERSION_FAILED',
                    'stage': self.jobs.get(job_id, {}).get('stage', 'Unknown')
                },
                room=job_id
            )
        finally:
            # COMMENT 1 FIX: Clean up temporary input file outside lock
            # This runs regardless of success, failure, or cancellation
            if audio_path and os.path.exists(audio_path):
                try:
                    os.unlink(audio_path)
                    logger.debug(f"Cleaned up temporary input file: {audio_path}")
                except OSError as e:
                    logger.warning(f"Failed to delete temporary input file {audio_path}: {e}")
    
    def _cleanup_expired_jobs(self):
        """Background cleanup thread"""
        while not self._shutdown.is_set():
            try:
                now = time.time()
                expired_jobs = []
                in_progress_expired = []

                with self.lock:
                    for job_id, job in list(self.jobs.items()):
                        status = job.get('status')

                        if status in {'queued', 'processing'}:
                            # Expire stuck in-progress jobs
                            if now - job['created_at'] > self.in_progress_ttl_seconds:
                                in_progress_expired.append(job_id)
                            continue

                        # Terminal jobs TTL
                        if status == 'completed':
                            effective_ttl = self.completed_ttl_seconds
                        elif status == 'failed':
                            effective_ttl = self.failed_ttl_seconds
                        else:
                            effective_ttl = self.ttl_seconds

                        timestamp = job.get('completed_at') or job.get('created_at', 0)

                        if now - timestamp > effective_ttl:
                            expired_jobs.append(job_id)

                # Handle in-progress timeouts
                for job_id in in_progress_expired:
                    with self.lock:
                        job = self.jobs.get(job_id)
                        if job:
                            job['status'] = 'failed'
                            job['error'] = 'Job timeout - stuck in progress'
                            job['completed_at'] = now
                    self._remove_job(job_id)

                # Handle terminal jobs
                for job_id in expired_jobs:
                    self._remove_job(job_id)

                logger.debug(f"Cleaned up {len(expired_jobs) + len(in_progress_expired)} expired jobs")

            except Exception as e:
                logger.error(f"Cleanup error: {e}")

            self._shutdown.wait(timeout=self.cleanup_interval)
    
    def _remove_job(self, job_id: str):
        """Remove job and cleanup files"""
        with self.lock:
            job = self.jobs.pop(job_id, None)
            if not job:
                return
        
        # Delete result file
        if job.get('result_path'):
            try:
                Path(job['result_path']).unlink(missing_ok=True)
            except Exception as e:
                logger.error(f"Failed to delete result file for {job_id}: {e}")
        
        logger.info(f"Removed expired job {job_id}")
    
    def start_cleanup_thread(self):
        """Start daemon cleanup thread"""
        self._cleanup_thread = threading.Thread(target=self._cleanup_expired_jobs, daemon=True)
        self._cleanup_thread.start()
    
    def shutdown(self):
        """Graceful shutdown"""
        self._shutdown.set()
        
        # Cancel all futures
        with self.lock:
            for job in self.jobs.values():
                future = job.get('future')
                if future:
                    future.cancel()
        
        self.executor.shutdown(wait=True)
        logger.info("JobManager shutdown complete")
