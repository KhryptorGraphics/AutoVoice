{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# AutoVoice Voice Cloning Demo\n\nInteractive tutorial for creating voice profiles using AutoVoice.\n\nThis notebook demonstrates:\n1. **Providing voice samples** - Upload files, record from microphone, or use existing files\n2. **Creating voice profiles** - Generate speaker embeddings from audio\n3. **Analyzing voice characteristics** - Extract pitch range and quality metrics\n4. **Creating multi-sample profiles** - Combine multiple recordings for robustness\n5. **Computing speaker similarity** - Compare different voice samples\n\n**Requirements**:\n- Core: `torch`, `librosa`, `numpy`, `matplotlib`\n- Optional (for upload): `ipywidgets` - `pip install ipywidgets`\n- Optional (for recording): `sounddevice`, `soundfile` - `pip install sounddevice soundfile`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and initialize the VoiceCloner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import dependencies\nimport sys\nsys.path.append('../src')  # Support editable installs with src/ layout\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio, display\nimport torch\n\nfrom auto_voice.inference import VoiceCloner\nfrom auto_voice.audio.pitch_extractor import SingingPitchExtractor\n\n# Check GPU availability\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\nif device == 'cuda':\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"CUDA Version: {torch.version.cuda}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. Data Setup (Optional)\n\nThis cell creates data directories for storing audio samples.\n\n**Not required if you plan to**:\n- Upload files directly (uses `./tmp/` automatically)\n- Record from microphone (uses `./tmp/` automatically)\n\n**Useful if you want to**:\n- Store sample files for reuse across notebooks\n- Organize multiple voice samples for multi-sample profiles"
  },
  {
   "cell_type": "code",
   "source": "# Create data directories\nfrom pathlib import Path\nimport os\n\n# Define data directories\ndata_dir = Path('../data')\nvoice_samples_dir = data_dir / 'voice_samples'\nsongs_dir = data_dir / 'songs'\n\n# Create directories\ndirectories_created = []\nfor dir_path in [voice_samples_dir, songs_dir]:\n    if not dir_path.exists():\n        dir_path.mkdir(parents=True, exist_ok=True)\n        directories_created.append(str(dir_path))\n        print(f\"\u2705 Created: {dir_path}\")\n    else:\n        print(f\"\u2139\ufe0f  Already exists: {dir_path}\")\n\n# Check for existing samples\nvoice_samples = list(voice_samples_dir.glob('*.wav')) + list(voice_samples_dir.glob('*.mp3'))\nsong_samples = list(songs_dir.glob('*.mp3')) + list(songs_dir.glob('*.wav'))\n\nprint(f\"\\n\ud83d\udcca Status:\")\nprint(f\"   Voice samples found: {len(voice_samples)}\")\nif voice_samples:\n    for sample in voice_samples[:5]:  # Show first 5\n        print(f\"      - {sample.name}\")\n    if len(voice_samples) > 5:\n        print(f\"      ... and {len(voice_samples) - 5} more\")\n\nprint(f\"   Song samples found: {len(song_samples)}\")\nif song_samples:\n    for sample in song_samples[:5]:  # Show first 5\n        print(f\"      - {sample.name}\")\n    if len(song_samples) > 5:\n        print(f\"      ... and {len(song_samples) - 5} more\")\n\nif not voice_samples:\n    print(f\"\\n\u2139\ufe0f  To add voice samples:\")\n    print(f\"   1. Place audio files (WAV, MP3, FLAC) in: {voice_samples_dir}\")\n    print(f\"   2. OR use the upload/recording options in later cells\")\n\nprint(f\"\\n\u2705 Data directories ready!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VoiceCloner\n",
    "cloner = VoiceCloner(device=device)\n",
    "\n",
    "print(\"VoiceCloner initialized successfully\")\n",
    "print(f\"Speaker encoder model: {cloner.speaker_encoder.__class__.__name__}\")\n",
    "print(f\"Embedding dimensions: {cloner.speaker_encoder.embedding_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Provide Voice Sample\n\nTo create a voice profile, you need to provide a voice sample (30-60 seconds recommended).\n\n**IMPORTANT: Follow these steps in order:**\n\n1. **Run the input setup cell first** to choose your audio source:\n   - Upload a file using the widget\n   - Record from microphone with `record_audio()`\n   - Set `audio_path` manually for existing files\n\n2. **Verify `audio_path` is set** using the status check cell\n\n3. **Run the load/validate cell** to load and analyze the audio\n\nThe notebook is designed for top-to-bottom execution. Do not skip the setup cell!"
  },
  {
   "cell_type": "markdown",
   "source": "### 2a. Voice Input Options\n\nChoose one of the following methods to provide your voice sample:\n\n**Option 1: Upload Audio File** (Recommended)\n- Upload a pre-recorded voice sample (30-60 seconds)\n- Supports WAV, MP3, FLAC, OGG formats\n- Best quality when recorded in quiet environment\n\n**Option 2: Record from Microphone**\n- Record directly in the notebook (requires microphone access)\n- Use `record_audio(duration=45)` function to start recording\n- Automatically saves to `./tmp/recorded_voice.wav`\n\n**Option 3: Use Existing File**\n- Specify path to existing audio file\n- Useful if you have files in `../data/voice_samples/`\n\n**Run the next cell to set up your audio input.**",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Audio Input Setup\nimport os\nfrom pathlib import Path\n\n# Create temp directory for uploads/recordings\nPath('./tmp').mkdir(exist_ok=True)\n\n# Initialize audio_path as None\naudio_path = None\n\nprint(\"Voice Input Options:\")\nprint(\"=\" * 60)\n\n# Option 1: File Upload Widget\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display, clear_output\n    \n    uploader = widgets.FileUpload(\n        accept='.wav,.mp3,.flac,.ogg',\n        multiple=False,\n        description='Upload Audio'\n    )\n    \n    upload_status = widgets.Output()\n    \n    def on_upload_change(change):\n        global audio_path\n        with upload_status:\n            clear_output()\n            if uploader.value:\n                # Get uploaded file\n                uploaded_file = list(uploader.value.values())[0]\n                filename = uploaded_file['metadata']['name']\n                audio_path = f'./tmp/{filename}'\n                \n                # Save file\n                with open(audio_path, 'wb') as f:\n                    f.write(uploaded_file['content'])\n                \n                # Get file size\n                file_size_mb = len(uploaded_file['content']) / (1024 * 1024)\n                \n                print(f\"\u2705 File uploaded: {filename}\")\n                print(f\"   Size: {file_size_mb:.2f} MB\")\n                print(f\"   Path: {audio_path}\")\n                print(\"\\n   Run the status check cell below to verify.\")\n    \n    uploader.observe(on_upload_change, names='value')\n    \n    print(\"\ud83d\udcc1 Option 1: Upload Audio File\")\n    display(uploader)\n    display(upload_status)\n    \n    UPLOAD_AVAILABLE = True\nexcept ImportError:\n    print(\"\u26a0\ufe0f  Option 1: Upload not available (install ipywidgets)\")\n    print(\"   pip install ipywidgets\")\n    UPLOAD_AVAILABLE = False\n\nprint()\n\n# Option 2: Microphone Recording\ntry:\n    import sounddevice as sd\n    import soundfile as sf\n    import numpy as np\n    \n    def record_audio(duration=45, sample_rate=44100):\n        \"\"\"\n        Record audio from microphone.\n        \n        Args:\n            duration: Recording duration in seconds (default: 45)\n            sample_rate: Sample rate in Hz (default: 44100)\n        \n        Returns:\n            Path to saved audio file\n        \"\"\"\n        global audio_path\n        \n        print(f\"\ud83c\udfa4 Recording {duration} seconds...\")\n        print(\"   Speak clearly into your microphone...\")\n        print(\"   3... 2... 1... Recording!\")\n        \n        # Record audio\n        audio_data = sd.rec(\n            int(duration * sample_rate), \n            samplerate=sample_rate, \n            channels=1,\n            dtype='float32'\n        )\n        sd.wait()  # Wait for recording to complete\n        \n        # Save to file\n        audio_path = './tmp/recorded_voice.wav'\n        sf.write(audio_path, audio_data, sample_rate)\n        \n        # Calculate duration and size\n        duration_actual = len(audio_data) / sample_rate\n        file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n        \n        print(f\"\\n\u2705 Recording complete!\")\n        print(f\"   Duration: {duration_actual:.1f}s\")\n        print(f\"   Size: {file_size_mb:.2f} MB\")\n        print(f\"   Path: {audio_path}\")\n        print(\"\\n   Run the status check cell below to verify.\")\n        \n        return audio_path\n    \n    print(\"\ud83c\udf99\ufe0f  Option 2: Record from Microphone\")\n    print(\"   Usage: record_audio(duration=45)  # Record 45 seconds\")\n    print(\"   Example: record_audio(duration=60)  # Record 60 seconds\")\n    \n    RECORDING_AVAILABLE = True\nexcept ImportError:\n    print(\"\u26a0\ufe0f  Option 2: Recording not available (install sounddevice & soundfile)\")\n    print(\"   pip install sounddevice soundfile\")\n    RECORDING_AVAILABLE = False\n\nprint()\n\n# Option 3: Use Existing File Path\nprint(\"\ud83d\udcc2 Option 3: Use Existing File\")\nprint(\"   Set audio_path manually:\")\nprint(\"   audio_path = '../data/voice_samples/my_voice.wav'\")\nprint()\n\n# Check for existing file as fallback\nfallback_path = '../data/voice_samples/my_voice.wav'\nif os.path.exists(fallback_path):\n    print(f\"\u2139\ufe0f  Found existing file: {fallback_path}\")\n    print(f\"   To use it, run: audio_path = '{fallback_path}'\")\nelse:\n    print(f\"\u2139\ufe0f  No default file found at: {fallback_path}\")\n\nprint(\"=\" * 60)\n\n# Final status\nif not UPLOAD_AVAILABLE and not RECORDING_AVAILABLE:\n    print(\"\\n\u26a0\ufe0f  WARNING: No audio input methods available!\")\n    print(\"   Install dependencies: pip install ipywidgets sounddevice soundfile\")\n    print(\"   Or manually set: audio_path = 'path/to/your/audio.wav'\")\nelif audio_path is None:\n    print(\"\\n\u2705 Audio input ready!\")\n    print(\"   Upload a file above, call record_audio(), or set audio_path manually\")\n    print(\"   Then run the status check cell below.\")\nelse:\n    print(f\"\\n\u2705 Audio file ready: {audio_path}\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check audio_path status\nimport os\n\nprint(\"Audio Input Status Check:\")\nprint(\"=\" * 60)\n\nif 'audio_path' not in globals():\n    print(\"\u274c audio_path is not defined\")\n    print(\"   Please run the input setup cell above first.\")\nelif audio_path is None:\n    print(\"\u26a0\ufe0f  audio_path is None\")\n    print(\"   Please upload a file, record audio, or set audio_path manually.\")\nelif not os.path.exists(audio_path):\n    print(f\"\u274c File does not exist: {audio_path}\")\n    print(\"   Please check the path and try again.\")\nelse:\n    # File exists - show details\n    file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n    print(f\"\u2705 Audio file ready!\")\n    print(f\"   Path: {audio_path}\")\n    print(f\"   Size: {file_size_mb:.2f} MB\")\n    print(f\"   Exists: Yes\")\n    print(\"\\n   You can now run the load/validate cell below.\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "source": "# Load and validate voice sample\nimport os\n\n# Check audio_path is configured\nif audio_path is None:\n    print(\"\u274c Error: No audio file configured\")\n    print(\"\\n   Please run the 'Audio Input Setup' cell above and:\")\n    print(\"   \u2022 Upload an audio file using the widget, OR\")\n    print(\"   \u2022 Call record_audio(duration=45) to record from microphone, OR\")\n    print(\"   \u2022 Set audio_path = 'path/to/your/audio.wav' manually\")\n    print(\"\\n   Then re-run this cell.\")\n    raise ValueError(\"audio_path not configured. Please configure audio input first.\")\n\n# Check file exists\nif not os.path.exists(audio_path):\n    print(f\"\u274c Error: Audio file not found: {audio_path}\")\n    print(\"\\n   Please check:\")\n    print(\"   \u2022 The file path is correct\")\n    print(\"   \u2022 The file exists at the specified location\")\n    print(\"   \u2022 You have permission to access the file\")\n    raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n\n# Validate file format\nvalid_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']\nfile_ext = os.path.splitext(audio_path)[1].lower()\nif file_ext not in valid_extensions:\n    print(f\"\u26a0\ufe0f  Warning: Unusual audio format: {file_ext}\")\n    print(f\"   Supported formats: {', '.join(valid_extensions)}\")\n    print(f\"   The file may still work, but results may vary.\")\n\n# Load audio with librosa\ntry:\n    print(f\"Loading audio file: {audio_path}\")\n    audio, sample_rate = librosa.load(audio_path, sr=None)\n    duration = len(audio) / sample_rate\n    file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n    \n    print(\"\\n\u2705 Audio loaded successfully!\")\n    print(f\"   File: {os.path.basename(audio_path)}\")\n    print(f\"   Duration: {duration:.2f} seconds\")\n    print(f\"   Sample rate: {sample_rate} Hz\")\n    print(f\"   Audio shape: {audio.shape}\")\n    print(f\"   File size: {file_size_mb:.2f} MB\")\n    \n    # Quality warnings\n    if duration < 30:\n        print(f\"\\n\u26a0\ufe0f  Warning: Audio is short ({duration:.1f}s)\")\n        print(f\"   Recommendation: Use 30-60s audio for best quality\")\n        print(f\"   Current length may reduce voice profile accuracy\")\n    elif duration > 90:\n        print(f\"\\n\u2139\ufe0f  Audio is long ({duration:.1f}s)\")\n        print(f\"   Processing may take longer, but quality will be good\")\n    \n    if sample_rate < 16000:\n        print(f\"\\n\u26a0\ufe0f  Warning: Low sample rate ({sample_rate} Hz)\")\n        print(f\"   Recommendation: Use \u226516kHz for better quality\")\n    \n    # Audio preview\n    print(\"\\n\ud83d\udd0a Audio Preview:\")\n    display(Audio(audio, rate=sample_rate))\n    \nexcept Exception as e:\n    print(f\"\\n\u274c Error loading audio file: {str(e)}\")\n    print(f\"\\n   Troubleshooting:\")\n    print(f\"   \u2022 Ensure the file is a valid audio file\")\n    print(f\"   \u2022 Try converting to WAV format\")\n    print(f\"   \u2022 Check if librosa is installed correctly\")\n    raise",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Audio\n",
    "\n",
    "Visualize the waveform and spectrogram of your voice sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot waveform\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.waveshow(audio, sr=sample_rate)\n",
    "plt.title('Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Plot spectrogram\n",
    "plt.subplot(1, 2, 2)\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "librosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Voice Characteristics\n",
    "\n",
    "Extract pitch range and quality metrics from the voice sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from auto_voice.audio.pitch_extractor import SingingPitchExtractor\n\n# Extract pitch\npitch_extractor = SingingPitchExtractor(device=device)\nf0, confidence = pitch_extractor.extract_f0(audio, sample_rate)\n\n# Filter voiced frames\nvoiced_mask = (f0 > 0) & (confidence > 0.8)\nf0_voiced = f0[voiced_mask]\n\n# Compute statistics\nf0_min = np.min(f0_voiced) if len(f0_voiced) > 0 else 0\nf0_max = np.max(f0_voiced) if len(f0_voiced) > 0 else 0\nf0_mean = np.mean(f0_voiced) if len(f0_voiced) > 0 else 0\n\n# Convert to note names\ndef hz_to_note(hz):\n    if hz == 0:\n        return \"N/A\"\n    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n    semitones = 12 * np.log2(hz / 440.0) + 69\n    note_idx = int(round(semitones)) % 12\n    octave = int(round(semitones)) // 12 - 1\n    return f\"{notes[note_idx]}{octave}\"\n\nmin_note = hz_to_note(f0_min)\nmax_note = hz_to_note(f0_max)\n\nprint(f\"Vocal Range:\")\nprint(f\"  Min: {f0_min:.2f} Hz ({min_note})\")\nprint(f\"  Max: {f0_max:.2f} Hz ({max_note})\")\nprint(f\"  Mean: {f0_mean:.2f} Hz\")\nprint(f\"  Range: {max_note} - {min_note}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Pitch Contour\n",
    "\n",
    "Visualize the pitch (F0) contour over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F0 contour\n",
    "plt.figure(figsize=(14, 4))\n",
    "times = np.arange(len(f0)) * (512 / sample_rate)  # Assuming hop_length=512\n",
    "plt.plot(times, f0, linewidth=0.5, alpha=0.7)\n",
    "plt.axhline(f0_mean, color='r', linestyle='--', label=f'Mean: {f0_mean:.1f} Hz')\n",
    "plt.axhline(f0_min, color='g', linestyle='--', label=f'Min: {f0_min:.1f} Hz ({min_note})')\n",
    "plt.axhline(f0_max, color='b', linestyle='--', label=f'Max: {f0_max:.1f} Hz ({max_note})')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('F0 (Hz)')\n",
    "plt.title('Pitch Contour')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Voice Profile\n",
    "\n",
    "Create a voice profile from the loaded audio sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create voice profile\n",
    "profile = cloner.create_voice_profile(\n",
    "    audio=audio_path,\n",
    "    user_id='demo_user',\n",
    "    profile_name='My Voice Demo'\n",
    ")\n",
    "\n",
    "print(\"Voice profile created successfully!\")\n",
    "print(f\"Profile ID: {profile['profile_id']}\")\n",
    "print(f\"User ID: {profile['user_id']}\")\n",
    "print(f\"Profile Name: {profile['profile_name']}\")\n",
    "print(f\"\\nAudio Info:\")\n",
    "print(f\"  Duration: {profile['audio_info']['duration_seconds']:.2f} seconds\")\n",
    "print(f\"  Sample Rate: {profile['audio_info']['sample_rate']} Hz\")\n",
    "print(f\"\\nVocal Range:\")\n",
    "print(f\"  Min: {profile['vocal_range']['min_note']} ({profile['vocal_range']['min_pitch_hz']:.2f} Hz)\")\n",
    "print(f\"  Max: {profile['vocal_range']['max_note']} ({profile['vocal_range']['max_pitch_hz']:.2f} Hz)\")\n",
    "print(f\"  Range: {profile['vocal_range']['range_semitones']} semitones\")\n",
    "print(f\"\\nQuality Metrics:\")\n",
    "print(f\"  SNR: {profile['quality_metrics']['snr_db']:.2f} dB\")\n",
    "print(f\"  Quality Score: {profile['quality_metrics']['quality_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Speaker Embedding\n",
    "\n",
    "Extract and visualize the speaker embedding (vector representation of voice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get speaker embedding\n",
    "embedding = profile['embedding']\n",
    "\n",
    "print(f\"Speaker Embedding:\")\n",
    "print(f\"  Shape: {embedding.shape}\")\n",
    "print(f\"  Norm: {np.linalg.norm(embedding):.4f}\")\n",
    "print(f\"  Mean: {np.mean(embedding):.4f}\")\n",
    "print(f\"  Std: {np.std(embedding):.4f}\")\n",
    "\n",
    "# Visualize embedding\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(embedding, linewidth=0.5)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Speaker Embedding (256-dimensional vector)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Sample Profile (Optional)\n",
    "\n",
    "Create a more robust profile from multiple voice samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create profile from multiple samples\n",
    "sample_paths = [\n",
    "    '../data/voice_samples/sample1.wav',\n",
    "    '../data/voice_samples/sample2.wav',\n",
    "    '../data/voice_samples/sample3.wav'\n",
    "]\n",
    "\n",
    "# Check if files exist\n",
    "import os\n",
    "existing_samples = [path for path in sample_paths if os.path.exists(path)]\n",
    "\n",
    "if len(existing_samples) > 1:\n",
    "    multi_profile = cloner.create_voice_profile_from_multiple_samples(\n",
    "        audio_paths=existing_samples,\n",
    "        user_id='demo_user',\n",
    "        profile_name='Multi-Sample Voice Profile'\n",
    "    )\n",
    "\n",
    "    print(\"Multi-sample profile created!\")\n",
    "    print(f\"Profile ID: {multi_profile['profile_id']}\")\n",
    "    print(f\"Number of samples: {len(existing_samples)}\")\n",
    "    print(f\"Quality Score: {multi_profile['quality_metrics']['quality_score']:.2f}\")\n",
    "else:\n",
    "    print(\"Skipping multi-sample profile (requires 2+ samples)\")\n",
    "    print(f\"Place audio files in ../data/voice_samples/ to enable this feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Speaker Similarity Comparison\n",
    "\n",
    "Compare similarity between different voice samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a second voice sample for comparison\n",
    "comparison_path = '../data/voice_samples/other_voice.wav'  # Update with your file\n",
    "\n",
    "if os.path.exists(comparison_path):\n",
    "    # Extract embedding for comparison sample\n",
    "    comparison_audio, _ = librosa.load(comparison_path, sr=sample_rate)\n",
    "    \n",
    "    # Create temporary profile\n",
    "    comparison_profile = cloner.create_voice_profile(\n",
    "        audio=comparison_path,\n",
    "        user_id='demo_user',\n",
    "        profile_name='Comparison Voice'\n",
    "    )\n",
    "    \n",
    "    comparison_embedding = comparison_profile['embedding']\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    similarity = cosine_similarity(\n",
    "        embedding.reshape(1, -1),\n",
    "        comparison_embedding.reshape(1, -1)\n",
    "    )[0, 0]\n",
    "    \n",
    "    print(f\"Speaker Similarity:\")\n",
    "    print(f\"  Cosine Similarity: {similarity:.4f}\")\n",
    "    \n",
    "    if similarity > 0.85:\n",
    "        print(\"  Result: Same speaker (>85% similarity)\")\n",
    "    elif similarity > 0.70:\n",
    "        print(\"  Result: Similar speakers (70-85% similarity)\")\n",
    "    else:\n",
    "        print(\"  Result: Different speakers (<70% similarity)\")\n",
    "    \n",
    "    # Visualize embedding comparison\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(embedding, label='Sample 1', linewidth=0.5, alpha=0.7)\n",
    "    plt.plot(comparison_embedding, label='Sample 2', linewidth=0.5, alpha=0.7)\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Speaker Embedding Comparison (Similarity: {similarity:.4f})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping similarity comparison (no comparison file found)\")\n",
    "    print(f\"Place another audio file at: {comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quality Assessment\n",
    "\n",
    "Assess the quality of your voice sample for voice cloning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality assessment\n",
    "duration = len(audio) / sample_rate\n",
    "snr = profile['quality_metrics']['snr_db']\n",
    "quality_score = profile['quality_metrics']['quality_score']\n",
    "\n",
    "print(\"Quality Assessment:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Duration check\n",
    "if duration >= 45:\n",
    "    print(f\"\u2705 Duration: {duration:.1f}s (Optimal: 45-60s)\")\n",
    "elif duration >= 30:\n",
    "    print(f\"\u26a0\ufe0f  Duration: {duration:.1f}s (Acceptable: 30-45s)\")\n",
    "    print(\"   Recommendation: Record 45-60s for best quality\")\n",
    "else:\n",
    "    print(f\"\u274c Duration: {duration:.1f}s (Too short: <30s)\")\n",
    "    print(\"   Recommendation: Record at least 30s, ideally 45-60s\")\n",
    "\n",
    "# SNR check\n",
    "if snr >= 20:\n",
    "    print(f\"\u2705 SNR: {snr:.1f} dB (Excellent: >20 dB)\")\n",
    "elif snr >= 15:\n",
    "    print(f\"\u2705 SNR: {snr:.1f} dB (Good: 15-20 dB)\")\n",
    "elif snr >= 10:\n",
    "    print(f\"\u26a0\ufe0f  SNR: {snr:.1f} dB (Fair: 10-15 dB)\")\n",
    "    print(\"   Recommendation: Record in quieter environment\")\n",
    "else:\n",
    "    print(f\"\u274c SNR: {snr:.1f} dB (Poor: <10 dB)\")\n",
    "    print(\"   Recommendation: Reduce background noise significantly\")\n",
    "\n",
    "# Overall quality\n",
    "if quality_score >= 0.8:\n",
    "    print(f\"\u2705 Overall Quality: {quality_score:.2f} (Excellent: >0.8)\")\n",
    "elif quality_score >= 0.6:\n",
    "    print(f\"\u2705 Overall Quality: {quality_score:.2f} (Good: 0.6-0.8)\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  Overall Quality: {quality_score:.2f} (Fair: <0.6)\")\n",
    "    print(\"   Recommendation: Improve recording quality\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nRecommendations for Best Quality:\")\n",
    "print(\"  \u2022 Record 45-60 seconds of speech or singing\")\n",
    "print(\"  \u2022 Use quiet environment with minimal background noise\")\n",
    "print(\"  \u2022 Maintain 6-12 inches from microphone\")\n",
    "print(\"  \u2022 Include variety: different pitches and dynamics\")\n",
    "print(\"  \u2022 Avoid clipping and distortion\")\n",
    "print(\"  \u2022 Use lossless formats (WAV, FLAC) when possible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. \u2705 Load and visualize voice samples\n",
    "2. \u2705 Extract pitch characteristics and vocal range\n",
    "3. \u2705 Create voice profiles with AutoVoice\n",
    "4. \u2705 Analyze speaker embeddings\n",
    "5. \u2705 Create multi-sample profiles for robustness\n",
    "6. \u2705 Compare speaker similarity\n",
    "7. \u2705 Assess voice sample quality\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Song Conversion**: Use your voice profile to convert songs\n",
    "  - See `song_conversion_demo.ipynb` for song conversion tutorial\n",
    "- **API Usage**: Integrate voice cloning into your applications\n",
    "  - See `docs/api_voice_conversion.md` for API documentation\n",
    "- **Production Deployment**: Deploy AutoVoice for production use\n",
    "  - See `docs/runbook.md` for operations guide\n",
    "\n",
    "### Resources\n",
    "\n",
    "- User Guide: `docs/voice_conversion_guide.md`\n",
    "- API Reference: `docs/api_voice_conversion.md`\n",
    "- Model Architecture: `docs/model_architecture.md`\n",
    "- Demo Scripts: `examples/demo_voice_conversion.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}